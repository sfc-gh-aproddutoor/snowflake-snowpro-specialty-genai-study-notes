[< Domain 1](./README.md) | **ðŸ“˜ 1.1 Snowflake Cortex Overview** | [Domain 2 >](../2_Snowflake_Gen_AI_and_LLM_Functions/README.md)
***

# 1.1 Snowflake Cortex Overview

This section provides a comprehensive overview of Snowflake Cortex, the platform's AI and machine learning service that enables developers to build intelligent applications using generative AI and Large Language Models (LLMs).

## What is Snowflake Cortex?

Snowflake Cortex is a fully managed service that provides industry-leading large language models (LLMs) from OpenAI, Anthropic, Meta, Mistral AI, and DeepSeek, along with vector functions for AI and ML workloads. It enables developers to build AI-powered applications directly within Snowflake without moving data to external platforms. All models are fully hosted in Snowflake, ensuring performance, scalability, and governance while keeping your data secure and in place.

### Key Capabilities

1. **Large Language Models (LLMs)**: Pre-trained models for text generation, analysis, and understanding
2. **Vector Functions**: Support for vector operations, embeddings, and similarity search
3. **ML Functions**: Machine learning capabilities for classification, prediction, and analysis
4. **Serverless Architecture**: Fully managed with automatic scaling and no infrastructure management

### How it Works

1. **Data Preparation**: Your data remains in Snowflake tables and views
2. **Function Calls**: Use SQL functions to invoke Cortex capabilities
3. **Processing**: Cortex processes data using state-of-the-art AI models
4. **Results**: Get structured results back as SQL data types

## Available LLM Models

Snowflake Cortex provides access to multiple leading LLM models:

### **Large Models (Best Performance)**
- **llama3.1-405b** - Meta's largest model for complex reasoning
- **claude-3.5-sonnet** - Anthropic's advanced model for sophisticated tasks
- **gpt-4o** - OpenAI's flagship multimodal model
- **mistral-large2** - Mistral's most capable model

### **Medium Models (Balanced Performance/Cost)**
- **llama3.1-70b** - Strong performance for most use cases
- **claude-3-haiku** - Fast and cost-effective from Anthropic
- **gpt-4o-mini** - OpenAI's efficient model
- **mixtral-8x7b** - Mixture of experts model
- **mistral-7b** - General-purpose model

### **Small Models (Cost-Optimized)**
- **llama3.1-8b** - Lightweight but capable
- **gemma-7b** - Google's efficient model
- **llama2-70b-chat** - Optimized for conversations
- **llama2-7b-chat** - Lightweight conversational model
- **deepseek-coder-6.7b** - Specialized for code generation

### **Embedding Models**
- **snowflake-arctic-embed-l** - Snowflake's large embedding model
- **snowflake-arctic-embed-m** - Snowflake's medium embedding model
- **e5-base-v2** - 768-dimensional general-purpose embeddings
- **multilingual-e5-large** - Multi-language embedding support

```sql
-- Example: Using different models for text generation
SELECT AI_COMPLETE(
    'mistral-large2',
    'Explain quantum computing in simple terms'
) AS explanation;

SELECT AI_COMPLETE(
    'claude-3.5-sonnet',
    'Write a Python function to calculate Fibonacci numbers'
) AS code_example;

-- Using legacy function (still supported)
SELECT SNOWFLAKE.CORTEX.COMPLETE(
    'llama3.1-70b',
    'Summarize the benefits of cloud computing'
) AS summary;
```

## Core Cortex Functions

### **Latest AI Functions (Recommended)**

**AI_COMPLETE()** - Updated text completion with latest models
```sql
SELECT AI_COMPLETE(
    'claude-3.5-sonnet',
    'Complete this story: Once upon a time in a digital world...'
) AS story_completion;
```

**AI_CLASSIFY()** - Enhanced classification with multi-label and image support
```sql
SELECT AI_CLASSIFY(
    'This movie was absolutely fantastic!',
    ['positive', 'negative', 'neutral']
) AS sentiment_classification;
```

**AI_FILTER()** - Boolean filtering with natural language conditions
```sql
SELECT AI_FILTER(
    'Is this text about technology?',
    review_text
) AS is_tech_related
FROM customer_reviews;
```

**AI_AGG()** - Aggregate insights across multiple rows
```sql
SELECT AI_AGG(
    customer_feedback,
    'Summarize the main themes in customer feedback'
) AS feedback_summary
FROM support_tickets
GROUP BY product_category;
```

**AI_SIMILARITY()** - Calculate embedding similarity between inputs
```sql
SELECT AI_SIMILARITY(
    'artificial intelligence',
    'machine learning'
) AS similarity_score;
```

### **Legacy Functions (Still Supported)**

**COMPLETE()** - Original text completion function
```sql
SELECT SNOWFLAKE.CORTEX.COMPLETE(
    'llama3.1-70b',
    'Complete this story: Once upon a time in a digital world...'
) AS story_completion;
```

**EXTRACT_ANSWER()** - Extract answers from text
```sql
SELECT SNOWFLAKE.CORTEX.EXTRACT_ANSWER(
    'What is the capital of France?',
    'France is a country in Europe. Paris is the capital and largest city of France.'
) AS answer;
```

### **Text Analysis Functions**

**SENTIMENT()** - Analyze sentiment
```sql
SELECT 
    review_text,
    SNOWFLAKE.CORTEX.SENTIMENT(review_text) AS sentiment_score
FROM customer_reviews;
```

**SUMMARIZE()** - Generate summaries
```sql
SELECT SNOWFLAKE.CORTEX.SUMMARIZE(
    long_document_text
) AS summary
FROM documents;
```

**TRANSLATE()** - Translate text between languages
```sql
SELECT SNOWFLAKE.CORTEX.TRANSLATE(
    'Hello, how are you?',
    'en',
    'es'
) AS spanish_translation;
```

### **Embedding Functions**

**EMBED_TEXT_768()** - Generate 768-dimensional embeddings
```sql
SELECT 
    document_id,
    document_text,
    SNOWFLAKE.CORTEX.EMBED_TEXT_768('e5-base-v2', document_text) AS embedding
FROM documents;
```

**EMBED_TEXT_1024()** - Generate 1024-dimensional embeddings
```sql
CREATE TABLE document_embeddings AS
SELECT 
    id,
    SNOWFLAKE.CORTEX.EMBED_TEXT_1024('snowflake-arctic-embed-m', content) AS embedding
FROM source_documents;
```

## Vector Operations

Snowflake provides built-in support for vector operations essential for AI applications:

### **Vector Data Types**
- **VECTOR(FLOAT, N)** - N-dimensional vector of floats
- **VECTOR(INT, N)** - N-dimensional vector of integers

### **Vector Functions**

**VECTOR_COSINE_SIMILARITY()** - Calculate cosine similarity
```sql
SELECT 
    doc1.id,
    doc2.id,
    VECTOR_COSINE_SIMILARITY(doc1.embedding, doc2.embedding) AS similarity
FROM document_embeddings doc1
CROSS JOIN document_embeddings doc2
WHERE doc1.id != doc2.id;
```

**VECTOR_L2_DISTANCE()** - Calculate Euclidean distance
```sql
SELECT 
    document_id,
    VECTOR_L2_DISTANCE(
        embedding, 
        SNOWFLAKE.CORTEX.EMBED_TEXT_768('e5-base-v2', 'search query')
    ) AS distance
FROM document_embeddings
ORDER BY distance
LIMIT 10;
```

## Building RAG Applications

Retrieval-Augmented Generation (RAG) is a common pattern with Cortex:

### **Step 1: Create Knowledge Base**
```sql
-- Create table with document embeddings
CREATE TABLE knowledge_base (
    id INT,
    document_text TEXT,
    embedding VECTOR(FLOAT, 768)
);

-- Populate with embeddings
INSERT INTO knowledge_base
SELECT 
    id,
    content,
    SNOWFLAKE.CORTEX.EMBED_TEXT_768('e5-base-v2', content)
FROM source_documents;
```

### **Step 2: Implement Similarity Search**
```sql
-- Function to find relevant documents
CREATE OR REPLACE FUNCTION find_relevant_docs(query_text TEXT)
RETURNS TABLE (id INT, document_text TEXT, similarity FLOAT)
AS $$
SELECT 
    id,
    document_text,
    VECTOR_COSINE_SIMILARITY(
        embedding,
        SNOWFLAKE.CORTEX.EMBED_TEXT_768('e5-base-v2', query_text)
    ) AS similarity
FROM knowledge_base
ORDER BY similarity DESC
LIMIT 5
$$;
```

### **Step 3: Generate Contextualized Responses**
```sql
-- RAG query function
CREATE OR REPLACE FUNCTION rag_query(user_question TEXT)
RETURNS TEXT
AS $$
WITH relevant_docs AS (
    SELECT document_text
    FROM TABLE(find_relevant_docs(user_question))
)
SELECT SNOWFLAKE.CORTEX.COMPLETE(
    'mistral-large',
    'Based on the following context, answer the question: ' || user_question || 
    '\n\nContext: ' || LISTAGG(document_text, '\n\n')
) AS response
FROM relevant_docs
$$;
```

## Performance Optimization

### **Best Practices**

1. **Batch Processing**: Process multiple records in single queries
```sql
-- Efficient batch embedding generation
SELECT 
    id,
    SNOWFLAKE.CORTEX.EMBED_TEXT_768('e5-base-v2', text_column) AS embedding
FROM large_text_table;
```

2. **Model Selection**: Choose appropriate models for your use case
- Use smaller models (7B) for simple tasks
- Use larger models (70B) for complex reasoning
- Use specialized models for specific domains

3. **Function Caching**: Leverage Snowflake's result caching
```sql
-- Results are automatically cached for identical function calls
SELECT SNOWFLAKE.CORTEX.COMPLETE('mistral-large', 'same prompt') AS result;
```

### **Cost Optimization**

1. **Token Management**: Monitor token usage with COUNT_TOKENS()
```sql
SELECT 
    prompt,
    SNOWFLAKE.CORTEX.COUNT_TOKENS('mistral-large', prompt) AS token_count
FROM prompts_table;
```

2. **Model Efficiency**: Balance model capability with cost
3. **Query Optimization**: Use efficient SQL patterns for batch processing

## Monitoring and Observability

### **Query History and Performance**
```sql
-- Monitor Cortex function usage
SELECT 
    query_text,
    execution_time,
    credits_used
FROM information_schema.query_history
WHERE query_text ILIKE '%CORTEX%'
ORDER BY start_time DESC;
```

### **Account Usage Views**
```sql
-- Monitor Cortex usage across account
SELECT 
    user_name,
    warehouse_name,
    SUM(credits_used) AS total_credits
FROM snowflake.account_usage.query_history
WHERE query_text ILIKE '%CORTEX%'
GROUP BY user_name, warehouse_name;
```

## Security and Governance

### **Access Control**
- Use standard Snowflake RBAC for Cortex functions
- Control access to underlying data and compute resources
- Monitor usage through audit logs

### **Data Privacy**
- Data processed by Cortex remains within your Snowflake account
- No data is sent to external services
- Comply with data residency requirements

### **Usage Policies**
```sql
-- Create usage policies for Cortex functions
CREATE OR REPLACE RESOURCE MONITOR cortex_monitor
WITH 
    CREDIT_QUOTA = 1000
    FREQUENCY = MONTHLY
    START_TIMESTAMP = CURRENT_TIMESTAMP()
    TRIGGERS
        ON 75 PERCENT DO NOTIFY
        ON 90 PERCENT DO SUSPEND
        ON 100 PERCENT DO SUSPEND_IMMEDIATE;
```

## Common Use Cases

1. **Customer Support**: Automated response generation and sentiment analysis
2. **Content Creation**: Marketing copy, documentation, and creative writing
3. **Data Analysis**: Extracting insights from unstructured text data
4. **Knowledge Management**: Building searchable knowledge bases with RAG
5. **Translation Services**: Multi-language content processing
6. **Document Processing**: Summarization and information extraction

## Limitations and Considerations

1. **Token Limits**: Each model has maximum token limits per request
2. **Rate Limits**: Concurrent request limits may apply
3. **Model Availability**: Not all models available in all regions
4. **Cost Structure**: Usage-based pricing model
5. **Language Support**: Varies by model and function

---

**Next Steps**: Continue to [Domain 2: Snowflake Gen AI & LLM Functions](../2_Snowflake_Gen_AI_and_LLM_Functions/README.md) to learn about specific LLM functions and their implementations.

***
[< Domain 1](./README.md) | **ðŸ“˜ 1.1 Snowflake Cortex Overview** | [Domain 2 >](../2_Snowflake_Gen_AI_and_LLM_Functions/README.md) 